<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Gearons | Code snippets for pytorch</title>
  <meta name="description" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta property="og:title" content="Code snippets for pytorch">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://gearons.org//posts/pytorch-notes">
  <meta property="og:description" content="">
  <meta property="og:site_name" content="Gearons">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:url" content="https://gearons.org//posts/pytorch-notes">
  <meta name="twitter:title" content="Code snippets for pytorch">
  <meta name="twitter:description" content="">

  
    <meta property="og:image" content="https://gearons.org//assets/og-image-ee46bbc61b334e821e81534b1fd43f3fee6f020ec174b3c2114445695fd48c01.jpg">
    <meta name="twitter:image" content="https://gearons.org//assets/og-image-ee46bbc61b334e821e81534b1fd43f3fee6f020ec174b3c2114445695fd48c01.jpg">
  

  <link href="https://gearons.org//feed.xml" type="application/rss+xml" rel="alternate" title="Gearons Last 10 blog posts" />

  

  

    
      <link rel="icon" type="image/x-icon" href="/assets/favicon-light-b2624f1aef1507a57b8ae1e334ba18341523adcff511393365e33e6c4cdc007b.ico">
      <link rel="apple-touch-icon" href="/assets/apple-touch-icon-light-87d1f2a3a19b1500e5c1626a0492025ca5f7f97d24540dc5900288e92112925a.png">
      <link rel="stylesheet" type="text/css" href="/assets/light-d5cd0e3eaa66b2ed98fb88a8443522c2a074034a960d3e41d1ca589152717bac.css">
    

  

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
             
</head>

<body>
  <main>
    <div class="grid grid-centered">
      <div class="grid-cell">
        <nav class="header-nav scrollappear">
  <a href="/" class="header-logo" title="Gearons">Gearons</a>
  <ul class="header-links">
    
      <li>
        <a href="/about" title="About me">
          <i style="vertical-align: sub; color: #018A7B;" class="material-icons">settings_applications</i>


        </a>
      </li>
    
    
    
      <li>
        <a href="https://scholar.google.com/citations?user=iuSBSHsAAAAJ&amp;hl=en" rel="noreferrer noopener" target="_blank" title="Google Scholar">
          <i style="vertical-align: sub; color: #018A7B;" class="material-icons">school</i>


        </a>
      </li>
    
    
    
      <li>
        <a href="https://github.com/gear" rel="noreferrer noopener" target="_blank" title="GitHub">
          <i style="vertical-align: sub; color: #018A7B;" class="material-icons">code</i>


        </a>
      </li>
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
      <li>
        <a href="https://steamcommunity.com/id/gearons" rel="noreferrer noopener" target="_blank" title="Steam">
          <i style="vertical-align: sub; color: #018A7B;" class="material-icons">videogame_asset</i>


        </a>
      </li>
    
    
    
    
    
    
    
  </ul>
</nav>



        <article class="article scrollappear">
          <header class="article-header">
            <h1>Code snippets for pytorch</h1>
            <p></p>
            <div class="article-list-footer">
  <span class="article-list-date">
    January 4, 2019
  </span>
  <span class="article-list-divider">-</span>
  <span class="article-list-minutes">
    
    
      12 minute read
    
  </span>
  <span class="article-list-divider">-</span>
  <div class="article-list-tags">
    
  </div>
</div>
          </header>

          <div class="article-content">
            <p>I am switching to pytorch and here are some piece of code that I think will be
useful to copy-paste later.</p>

<hr>

<h2 id="data">Data</h2>

<p>Pytorch handles data quite cleanly. Data is loaded as tensors and then 
iterated using an iterator.</p>

<h3 id="example-1-cifar-10-dataset">Example 1: CIFAR-10 dataset</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torch.utils.data.sampler</span> <span class="kn">import</span> <span class="n">SubsetRandomSampler</span>

<span class="c1"># number of subprocesses to use for data loading
</span><span class="n">num_workers</span> <span class="o">=</span> <span class="mi">0</span>
<span class="c1"># how many samples per batch to load
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">20</span>
<span class="c1"># percentage of training set to use as validation
</span><span class="n">valid_size</span> <span class="o">=</span> <span class="mf">0.2</span>

<span class="c1"># convert data to a normalized torch.FloatTensor
</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
    <span class="p">])</span>

<span class="c1"># choose the training and test datasets
</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="s">'data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                              <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="s">'data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                             <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

<span class="c1"># obtain training indices that will be used for validation
</span><span class="n">num_train</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_train</span><span class="p">))</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
<span class="n">split</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">valid_size</span> <span class="o">*</span> <span class="n">num_train</span><span class="p">))</span>
<span class="n">train_idx</span><span class="p">,</span> <span class="n">valid_idx</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">split</span><span class="p">:],</span> <span class="n">indices</span><span class="p">[:</span><span class="n">split</span><span class="p">]</span>
 
<span class="c1"># define samplers for obtaining training and validation batches
</span><span class="n">train_sampler</span> <span class="o">=</span> <span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="n">train_idx</span><span class="p">)</span>
<span class="n">valid_sampler</span> <span class="o">=</span> <span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="n">valid_idx</span><span class="p">)</span>

<span class="c1"># prepare data loaders (combine dataset and sampler)
# when sampler is specified, shuffle parameter must be False 
# because sampler already specifies how data is drawn from the dataset.
</span><span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">sampler</span><span class="o">=</span><span class="n">train_sampler</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
<span class="n">valid_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
    <span class="n">sampler</span><span class="o">=</span><span class="n">valid_sampler</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
    <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>

<span class="c1"># specify the image classes
</span><span class="n">classes</span> <span class="o">=</span> <span class="p">[</span><span class="s">'airplane'</span><span class="p">,</span> <span class="s">'automobile'</span><span class="p">,</span> <span class="s">'bird'</span><span class="p">,</span> <span class="s">'cat'</span><span class="p">,</span> <span class="s">'deer'</span><span class="p">,</span>
           <span class="s">'dog'</span><span class="p">,</span> <span class="s">'frog'</span><span class="p">,</span> <span class="s">'horse'</span><span class="p">,</span> <span class="s">'ship'</span><span class="p">,</span> <span class="s">'truck'</span><span class="p">]</span>
</code></pre></div></div>

<p>In the example above, the three iterators <code class="highlighter-rouge">train_loader</code>, <code class="highlighter-rouge">valid_loader</code>, 
and <code class="highlighter-rouge">test_loader</code> iterate through all pairs of (data, target)s. The training
process for some given <code class="highlighter-rouge">model</code>, <code class="highlighter-rouge">optimizer</code>, and <code class="highlighter-rouge">criterion</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># number of epochs to train the model
</span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">8</span> 
<span class="c1"># track change in validaiton loss
</span><span class="n">valid_loss_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span> 

<span class="c1"># start training
</span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># keep track of training and validation loss
</span>    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">valid_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="c1">###################
</span>    <span class="c1"># train the model #
</span>    <span class="c1">###################
</span>    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="c1"># move tensors to GPU if CUDA is available
</span>        <span class="k">if</span> <span class="n">train_on_gpu</span><span class="p">:</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">target</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="c1"># clear the gradients of all optimized variables because by default
</span>        <span class="c1"># optimizer accumulates gradients after every batch. This design is
</span>        <span class="c1"># convenient for recurrent neural networks
</span>        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="c1"># forward pass: compute predicted outputs by passing inputs to the model
</span>        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="c1"># calculate the batch loss
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="c1"># backward pass: compute gradient of the loss with respect to model parameters
</span>        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="c1"># perform a single optimization step (parameter update)
</span>        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="c1"># update training loss
</span>        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1">######################    
</span>    <span class="c1"># validate the model #
</span>    <span class="c1">######################
</span>    <span class="n">model</span><span class="o">.</span><span class="nb">eval</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">valid_loader</span><span class="p">:</span>
        <span class="c1"># move tensors to GPU if CUDA is available
</span>        <span class="k">if</span> <span class="n">train_on_gpu</span><span class="p">:</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">target</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="c1"># forward pass: compute predicted outputs by passing inputs to the model
</span>        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="c1"># calculate the batch loss
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="c1"># update average validation loss 
</span>        <span class="n">valid_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># calculate average losses
</span>    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">train_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">valid_loss</span> <span class="o">=</span> <span class="n">valid_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="c1"># print training/validation statistics 
</span>    <span class="k">print</span><span class="p">(</span><span class="s">'Epoch: {} </span><span class="se">\t</span><span class="s">Training Loss: {:.6f} </span><span class="se">\t</span><span class="s">Validation Loss: {:.6f}'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span>
        <span class="n">epoch</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">valid_loss</span><span class="p">))</span>
    <span class="c1"># save model if validation loss has decreased
</span>    <span class="k">if</span> <span class="n">valid_loss</span> <span class="o">&lt;=</span> <span class="n">valid_loss_min</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'Validation loss decreased ({:.6f} --&gt; {:.6f}).  Saving model ...'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span>
        <span class="n">valid_loss_min</span><span class="p">,</span>
        <span class="n">valid_loss</span><span class="p">))</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s">'model_cifar.pt'</span><span class="p">)</span> <span class="c1"># state_dict() is a function call 
</span>        <span class="n">valid_loss_min</span> <span class="o">=</span> <span class="n">valid_loss</span>
</code></pre></div></div>

<p>In this paper, the author views Szemeredi Regularity Lemma from the information
theoric perspective. Such point of view not only clarifies the Regularity Lemma,
but also allows applications of other techniques (information theory, ergodic
theory) to proving and improving the regularity lemma.</p>

<p>Regularity Lemma is a building stone to the Szemeredi Theorem. The theorem
states that in a <a href="https://en.wikipedia.org/wiki/Natural_density">positive density</a>
subset of natural numbers, there exists an arbitarily large arithmetic progression.
This results relates strongly to the 
<a href="https://en.wikipedia.org/wiki/Ergodic_theory">ergodic theory</a>.</p>

<p>Instead of studying dense graph, in this paper, the author uses graphs and 
bi-paritite graphs as an analogue to random variables. Suppose there are two 
random variables $x_1$ and $x_2$ mapping from the vertices space 
($V_1$ and $V_2$) to some probability measurement.</p>

<p>There is a recent paper from Cambridge (probably sumitted to ICML 2019) that
connect ergodic theory with machine learning. It was published on 
<a href="https://arxiv.org/pdf/1811.07192.pdf">arXiv</a> with the title “The Theory and
Algorithm of Ergodic Inference”.</p>

<p>(Dec 26 – paused)</p>

<h3 id="1-introduction">1. Introduction</h3>

<h2 id="main-ideas-and-contributions">Main ideas and contributions</h2>

<ol>
  <li>
    <p>Starting from a skewed stacked RNN architecture, the authors proposed <strong>a novel
RNN where each hidden unit is parameterized by a high rank tensor (≥2)</strong>.</p>

    <p><img src="/img/trnn.png" alt="sRNN and tRNN"></p>

    <p>The image above compares a three hidden layers (depth L = 3) skewed recurrent neural network with the proposed model.
 The tRNN model here has only one hidden layer, but its hidden units are parameterized by a P-by-M matrix rather than
 a single vector. Furthermore, the interaction between hidden units are captured by the convolution operation (defined
 later) to take advantages of the tensor representation. According to the authors, the first dimension of the hidden units is “locally connected” in order to share parameters, while the second dimension is “fully connected” for global interaction. This idea will be clearer when we discuss the convolution. In general, the construction of a hidden unit output is computed as following (<script type="math/tex">\circledast</script> is the convolution operator):</p>

    <script type="math/tex; mode=display">H^\text{cat}_{t-1, p} = \left\{ 
 \begin{array}{l}
 x_t W^x + b^x, \text{ if } p = 1 \\ 
 h_{t-1, p-1}, \text{ else } %_
 \end{array}
 \right. \ \ \ \
 \begin{array}{l}
 A_t = H^\text{cat}_{t-1} \circledast \{W^h, b^h\} \\
 H_t = \phi(A_t) \\
 y_t = \varphi(h_{t+L-1, p} W^y + b^y)
 \end{array}</script>

    <p>Note that the actual output at <script type="math/tex">y_t</script> is computed using the last tensor (in this case it is a vector) of 
 the hidden tensor <script type="math/tex">H_{t+L-1}</script>. As in the figure above, <script type="math/tex">y_t</script> is computed from <script type="math/tex">h^3_{t+2}</script> - the last 
 layer of the hidden unit <script type="math/tex">H_{t+2}</script>. Also, the implicit depth P = L = 3 leads us to the same computation.</p>
  </li>
  <li>
    <p>The paper introduces <strong>cross-layer convolution and memory cell convolution (for the LSTM extension)</strong>. The explanation
to the convolution is presented in the second section. Note that in this post, I moved the time notation to the top of
each symbol when it’s convenient so that the subscript contains only indexing variables (e.g. <script type="math/tex">A_{t, p, m^o}</script> becomes <script type="math/tex">A^t_{p, m^o}</script>).</p>
  </li>
  <li>
    <p>The 2D-tRNN model is further <strong>extended to LSTM and higher order tensors (3D)</strong>.</p>

    <script type="math/tex; mode=display">\begin{array}{l}
 [A^g_t, A^i_t, A^f_t, A^o_t] = H^\text{cat}_{t-1} \circledast \{W^h, b^h\} \\
 [G_t, I_t, F_t, O_t] = [\phi{A^g_t}, \sigma{A^i_t}, \sigma{A^f_t}, \sigma{A^o_t}] \\
 \text{Memory cell: } C_t = G_t \odot I_t + C_{t-1} \odot F_t \in R^{P \times M} \\
 H_t = \phi(C_t) \odot O_t 
 \end{array}</script>

    <p>This extension to LSTM is pretty straight-forward as each gate is computed using the convolution operator
 <script type="math/tex">\circledast</script> in lieu of the standard matrix multiplication. For the higher order tensors extension, the concatenated
 tensor is constructed by appending the projection (multiplied with weights, added with bias) of <script type="math/tex">x_t</script> to one 
 <em>corner</em> of the hidden unit tensor. This can be understood as going down the tensor dimension-wise, when you reach
 a 2D matrix with row size of M, append <script type="math/tex">x_t W^x + b^x</script> to it. In the same way, <script type="math/tex">y_t</script> is generated with the
 opposite corner.</p>
  </li>
</ol>

<h2 id="dissecting-convolution">Dissecting convolution</h2>

<p>It took me sometime to fully grasp the author’s idea <img class="emoji" title=":dizzy_face:" alt=":dizzy_face:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f635.png" height="20" width="20">. Despite that “sometime”, my understanding can be
captured in a single image (and now I feel silly). In the case of 2D hidden units, the operation and the dimensionality 
of each tensor is:</p>

<script type="math/tex; mode=display">A_t = H^\text{cat}_{t-1} \circledast \{W^h, b^h\}, \text{ where: } \ \ \  
\begin{array}{l}
A_t \in R^{P \times M^o} \\
H^\text{cat}_{t-1} \in R^{(P+1) \times M} \\
W^h \in R^{K \times M^i \times M^o} \\
b^h \in R^{M^o}
\end{array}</script>

<p>In here, <script type="math/tex">A_t</script> is the activation tensor. <script type="math/tex">H^\text{cat}_{t-1}%_</script> represents the concatenation of a hidden unit’s 
rank-2 tensor output (matrix) and the input vector from the layer above it (in this case, it is the input vector 
<script type="math/tex">x_t</script>). From the skewed sRNN figure above, the concatenation is pretty clear: <script type="math/tex">h_t</script> is pointed to by <script type="math/tex">x_t</script> and
<script type="math/tex">h_{t-1}</script>, hence the tensor used in computing <script type="math/tex">A_t</script> and <script type="math/tex">h_t</script> will be the concatenation between <script type="math/tex">x_t</script> and
<script type="math/tex">h_{t-1}</script>. The same principle applies for the tRNN. The convolution kernel consists of weight <script type="math/tex">W^h</script> and bias <script type="math/tex">b^h</script>.
<script type="math/tex">W^h</script> is a rank-3 tensor of K filters, each filters has <script type="math/tex">M^i</script> input channels and <script type="math/tex">M^o</script> output channels. In this
paper, the authors noted that they let <script type="math/tex">M = M^i = M^o</script> for simplicity. The detail of the convolution is given in
the supplementary document:</p>

<script type="math/tex; mode=display">A^t_{p, m^o} = \sum^K_{k=1} \left( \sum^{M^i}_{m^i=1} H^{cat; t-1}_{p - \frac{K-1}{2}+k, m^i} \cdot W^k_{k,m^i,m^o}  \right) + b^h_{m^o}</script>

<p>It might sound obvious, but it is easier for me to think of the indices as “selector”. For example, <script type="math/tex">A^t_{p, m^o}</script>
is the element <script type="math/tex">\square</script> of tensor <script type="math/tex">A^t</script> that is selected by <script type="math/tex">(p, m^o)</script>. Usually, the “selector” is lowercase
and the total number of element in a dimension is uppercase. In the figure below, I circled in red the “selectors”.</p>

<p><img src="/img/rnn_conv.png" alt="sRNN and tRNN"></p>

<p>It might helps with a kind of story. The matrix <script type="math/tex">A^t \in R^{P \times M^o}</script> is what we need to compute for the next time 
step. We set out to compute each element of this matrix. <script type="math/tex">A^t_{p, m^o}</script> is given by the convolution operator defined
in the formula above. In the figure, the gray small box represents <script type="math/tex">A^t_{p, m^o}</script>. The two selector <script type="math/tex">p</script> and
<script type="math/tex">m^o</script> control the center of the convolution in <script type="math/tex">H^{\text{cat}; t-1}</script> and which output channel to pick in <script type="math/tex">W^h</script> 
respectively. For example, if <script type="math/tex">K=5</script> and where want to computer <script type="math/tex">A^t</script> at <script type="math/tex">(p=3, m^o=3)</script>, then for each slice of
<script type="math/tex">W^h</script>, the 5 columns associated with <script type="math/tex">m^o=3</script> will be picked out. Next, on <script type="math/tex">H^{\text{cat}; t-1}</script>, there are also 5 
rows selected. Since <script type="math/tex">p=3</script>, the index of these row vectors are <script type="math/tex">\{2,3,4,5,6\}</script> (centered at <script type="math/tex">p+1=4</script>). These 5 pairs
of vectors are indexed by <script type="math/tex">k = \{1,2,3,4,5\}</script>. Sum of the dot products of the pairs is <script type="math/tex">A^t_{p, m^o}</script>.
Note that the authors use zero-padding to keep the shape of output same as the input. In the case of memory cell 
convolution, the values used in padding are the border values to avoid interference with the memory values.</p>

<h2 id="evaluations">Evaluations</h2>

<p>The authors uses three main tasks to demonstrate the effectiveness of their proposed model:</p>

<ol>
  <li>
    <p><strong>Algorithmic tasks</strong> consist of learning to sum two 15-digit numbers and learning to repeat the input sequence.</p>

    <div class="highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>  Sum two 15-digit integers    ||   Repeat the input
  Input : --2545-9542-------   ||   Input : -hiworld----------
  Output: -----------12087--   ||   Output: --------hiworld--- 
</code></pre></div>    </div>
    <p>The advantage of the proposed model (3D-tLSTM with Channel Normalization) is that it requires much less training
 samples to reach more than 99 percent accuracy compared with Stacked LSTM and Grid LSTM. However, there are no
 mention to the training time or other modification of tLSTM. Furthermore, the best performing models have 7 and 10
 layers depth. There are not much explanation for these hyper-parameters. The 7-layer requires less training samples
 than the 10-layer in addition task, but the 10-layer in turn requires much less samples in memorization. I expected
 the 7-layer model requires less samples in both tasks.</p>
  </li>
  <li>
    <p><strong>MNIST classification</strong> tasks consist of normal MNIST and randomized pixel sequence called pMNIST. In these tasks, 
the pixels of an hand-written digit image are fed into the neural nets as a sequence. In this task, I do not see any
advantage of using tLSMT compared with state-of-the-art methods such as DilatedGRU.</p>
  </li>
  <li>
    <p><strong>Wikipedia language modeling</strong> task deal with next-character prediction on the Hutter Prize Wikipedia dataset. Similar
to the aforementioned MNIST tasks, there are no clear win for tLSTM compared with Large FS-LSTM-4 method (in term of
both BPC and number of parameters).</p>
  </li>
</ol>

<h2 id="why-tensors">Why tensors?</h2>

<p>It is true that we can design a “vector” recurrent neural net that works in the same way as the proposed tRNN here. After
all, the variables is stored in arrays on our computer. However, tensors represent a concrete way to think about a “block
of numbers”, and more importantly, we can define and argue about convolution easily with it. Let’s take image data as 
an example. The image below shows the popular 2D convolution operation. Tensor representation gives us a concrete way
to think about color channels and its corresponding channels in each convolution kernel. Furthermore, notice that we
“scan” each convolution channel in the intensity dimension (on the matrices) but not the color dimension. As such, the
weights in the intensity dimension are shared. Similarly, in recurrent neural networks, the tensor hidden unit in some
sense enables a more abstract representation and allow weight sharing.</p>

<p><img src="/img/2d_conv.png" alt="sRNN and tRNN"></p>

<h2 id="conclusion">Conclusion</h2>

<p>This paper proposes a nice way to increase the structural depth of a recurrent neural network model. Instead of 
parameterizing hidden units with vectors, tRNN modeled hidden units as tensors for more efficient weight sharing
and implicit depth. Such approach greatly reduces the number of parameters in a recurrent neural network while 
maintaining the depth. tRNN model is also extended to use LSTM module and higher order (3D) tensor for better performance
and data abstraction. The effectiveness of tLSTM is demonstrated on three different tasks in which tLSTM achieve 
state-of-the-art performance with some improvement on number of parameters (minor) and required number of training
samples. On the other hand, while the proposed model might improve running time and number of parameters, there was no
discussion on the training time and training complexity of tLSTM. It would be interesting to implement the 2D and 3D models
to understand the benefit of tLSTM better.</p>

<p>In this post, I wrote about my understanding and commented on the paper “Wider and Deeper, Cheaper and Faster:
Tensorized LSTMs for Sequence Learning” by Zhen He, Shaobing Gao, Liang Xiao, Daxue Liu, Hangen He, and David Barber.
I left out some details such as Channel Normalization or the constraints on <script type="math/tex">\{L, P, K\}</script>. These minor optimization
tricks can be found on the paper. After this post, I plan to implement this technique to see if it is suitable for my
current work. In particular, I would like to see if the training cost can potentially be reduced for a stacked LSTM
approach to model product names.</p>

          </div>
          <div class="article-share">
            
            
            <a href="https://twitter.com/home?status=Code+snippets+for+pytorch%20-%20https://gearons.org//posts/pytorch-notes" title="Share on Twitter" rel="noreferrer noopener" target="_blank">
              <svg viewbox="0 0 512 512"><path d="M492 109.5c-17.4 7.7-36 12.9-55.6 15.3 20-12 35.4-31 42.6-53.6 -18.7 11.1-39.4 19.2-61.5 23.5C399.8 75.8 374.6 64 346.8 64c-53.5 0-96.8 43.4-96.8 96.9 0 7.6 0.8 15 2.5 22.1 -80.5-4-151.9-42.6-199.6-101.3 -8.3 14.3-13.1 31-13.1 48.7 0 33.6 17.2 63.3 43.2 80.7C67 210.7 52 206.3 39 199c0 0.4 0 0.8 0 1.2 0 47 33.4 86.1 77.7 95 -8.1 2.2-16.7 3.4-25.5 3.4 -6.2 0-12.3-0.6-18.2-1.8 12.3 38.5 48.1 66.5 90.5 67.3 -33.1 26-74.9 41.5-120.3 41.5 -7.8 0-15.5-0.5-23.1-1.4C62.8 432 113.7 448 168.3 448 346.6 448 444 300.3 444 172.2c0-4.2-0.1-8.4-0.3-12.5C462.6 146 479 129 492 109.5z"></path></svg>
            </a>
            <a href="https://www.facebook.com/sharer/sharer.php?u=https://gearons.org//posts/pytorch-notes" title="Share on Facebook" rel="noreferrer noopener" target="_blank">
              <svg viewbox="0 0 512 512"><path d="M288 192v-38.1c0-17.2 3.8-25.9 30.5-25.9H352V64h-55.9c-68.5 0-91.1 31.4-91.1 85.3V192h-45v64h45v192h83V256h56.4l7.6-64H288z"></path></svg>
            </a>
          </div>

          
        </article>
        <footer class="footer scrollappear">
  <p>
    Opinions are my own. Hoang NT, 2020.
  </p>
</footer>

      </div>
    </div>
  </main>
  

<script type="text/javascript" src="/assets/vendor-2c224c53eb697c739f9490c38819a72184f09472739fd9e492272ef174090428.js"></script>


  <script type="text/javascript" src="/assets/webfonts-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.js"></script>



  <script type="text/javascript" src="/assets/scrollappear-e2da8ea567e418637e31266cc5302126eaa79f62a2273739086358b589a89ee6.js"></script>


<script type="text/javascript" src="/assets/application-cfde13ac81ddaf4351b2e739603e2baf688d0fcc9aba613fe62bbb1c7b037fb9.js"></script>



</body>
</html>
